{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026ac02c",
   "metadata": {},
   "source": [
    "## Modeling a non-negative matrix factorization topic model to identify and analyze the historical evolution of anthropogenic climate change impacts on water resources. \n",
    "\n",
    "### by Tanay Tunçer\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1 Data <br>\n",
    "2 Data pre-processing <br>\n",
    "3 Exploratory Data Analysis <br>\n",
    "4 Model parameter <br>\n",
    "5 Topic Coherence Cv <br>\n",
    "6 Latent Dirichlet Allocation <br>\n",
    "7 Non-negative Matrix Factorization \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Introduction \n",
    "\n",
    "Anthropogenic climate change represents one of the greatest challenges of the 21st century and is the subject of research to predict what economic, socio-economic and environmental changes can be expected in the future. The cause of climate change can be traced back to pre-industrial times and began with the first artificial emission of greenhouse gases into the atmosphere, which had a direct impact on the climate system. According to the Intergovernmental Panel on Climate Change, limiting warming to 1.5 degrees Celsius or 2.0 degrees Celsius is not achievable unless greenhouse gas emissions are reduced immediately and on a large scale. Climate change is triggering a variety of different changes in different regions, which will intensify as greenhouse gas emissions continue. Climate change is associated with changes in the water cycle, such as increasing water vapor content of the atmosphere, changing precipitation patterns, intensity and extremes, rising sea levels, decreasing snow and ice cover in mountains and water basins, flooding and drought, and changes in soil moisture. As a result of this challenge, it is important to improve knowledge of the effects of climate change on water as a resource. The evaluation of the practical suitability of the algorithm is assessed in this example by identifying the most influential impacts of climate change on water as a resource. The implemented models should be able to identify descriptive words that summarize the identified concepts as concisely as possible. The basis is the use of a collection of scientific articles with the highest consensus on the topic area to capture the most important topics on that area. The respective background topics of the research area are thus not taken into account.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy import stats\n",
    "import pingouin as pg\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.get_option(\"display.max_rows\")\n",
    "\n",
    "%load_ext jupyternotify\n",
    "from tqdm import tqdm, tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ec32a",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dateipfad ändern. Bitte beachten Sie, dass die Datei automatisch aus dem Dateipfad gelesen wird.\n",
    "path = \"C:/Users/tanaytuncer/Desktop/507145_Tanay_Tuncer_Bachelor/data\"\n",
    "\n",
    "#print(type(os.listdir(path)))\n",
    "for p in tqdm_notebook(range(1)):   \n",
    "    for document in os.listdir(path):\n",
    "        document_dir = (path + \"/\" + document)\n",
    "        print(document_dir)\n",
    "\n",
    "    text = pd.read_csv(document_dir, delimiter = \",\")\n",
    "    text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25329cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd86c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951fb35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text[\"Cited by\"] = text[\"Cited by\"].fillna(0)\n",
    "\n",
    "text.drop(text[text[\"Abstract\"]==\"[No abstract available]\"].index, inplace=True)\n",
    "text = text[text[\"Cited by\"] >= 150]\n",
    "\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218fa35",
   "metadata": {},
   "source": [
    "## 2. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = text.copy()\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    text = [x for x in tokens if x not in nltk.corpus.stopwords.words(\"english\")]\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(tokens):\n",
    "    import string\n",
    "    text = \" \".join([x for x in tokens if x not in string.punctuation])\n",
    "    text = \" \".join([x for x in tokens if x not in string.digits])\n",
    "    return text\n",
    "\n",
    "def remove_words(tokens):\n",
    "    words = [\"δ18o\", \"paper\"]\n",
    "    text = [x for x in tokens if x not in words]\n",
    "    text = [x for x in text if len(x) >= 3]\n",
    "    #text = [x for x in text if x != \",\"]\n",
    "    return text\n",
    "\n",
    "    \n",
    "def get_pos_tag(pos_tag):\n",
    "    if pos_tag in [\"JJ\", \"JJR\", \"JJS\"]:\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag in [\"RB\", \"RBR\", \"RBS\"]:\n",
    "        return wordnet.ADV\n",
    "    elif pos_tag in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]:\n",
    "        return wordnet.VERB\n",
    "    else: \n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_words(tokens):\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    words = \" \".join([WordNetLemmatizer().lemmatize(i) for i in tokens])\n",
    "    return words\n",
    "\n",
    "def extract_noun (tokens):\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    tags = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
    "    words = [i[0] for i in pos_tags if i[1] in tags]\n",
    "    return words\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc2f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%notify\n",
    "for p in tqdm_notebook(range(10)):    \n",
    "    corpus[\"Abstract\"] = corpus[\"Abstract\"].map(lambda x: x.lower())\n",
    "    corpus[\"Abstract\"] = corpus[\"Abstract\"].map(lambda x: RegexpTokenizer(r\"\\w+\").tokenize(x))\n",
    "    corpus[\"Abstract\"] = corpus[\"Abstract\"].apply(lambda x: remove_words(x))\n",
    "    corpus[\"Abstract\"] = corpus[\"Abstract\"].map(lambda x: remove_stopwords(x))\n",
    "    corpus[\"Abstract\"] = corpus[\"Abstract\"].apply(lambda x: extract_noun(x))\n",
    "    corpus[\"Abstract\"] = corpus[\"Abstract\"].apply(lambda x: lemmatize_words(x))\n",
    "print(\"Data pre-processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af235aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original data: \" + text[\"Abstract\"][0])\n",
    "print(\"\")\n",
    "print(\"Pre-processed data: \" + corpus[\"Abstract\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21035263",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafed4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors1 = [\"#023373\"]\n",
    "colors2 = [\"#023373\", \"#979797\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8006c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(df, x, y, z):\n",
    "    \"\"\"\n",
    "    Plot line chart.\n",
    "    \n",
    "    df = dataframe \n",
    "    x = categorical variable\n",
    "    y = numerical variable \n",
    "    z = color_code\n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.line(\n",
    "        data_frame = df,\n",
    "        x = x, \n",
    "        y = y,\n",
    "        color = z,\n",
    "        color_discrete_sequence= colors2,\n",
    "        template=\"simple_white\",\n",
    "        width=1000,        \n",
    "        height=400,\n",
    "        log_x = False\n",
    "    )\n",
    "        \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(df, x, y):\n",
    "    \"\"\"\n",
    "    Plot bar chart.\n",
    "    \n",
    "    df = dataframe\n",
    "    x = categorical variable\n",
    "    y = numerical variable \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.bar(\n",
    "        data_frame = df,\n",
    "        x = x,\n",
    "        y = y,\n",
    "        color_discrete_sequence=[\"#03658C\"],\n",
    "        template=\"simple_white\",\n",
    "        orientation = \"v\",\n",
    "        text = y,\n",
    "        facet_col = \"Period\",\n",
    "        facet_col_wrap=2,\n",
    "        facet_row_spacing = 0.15,        \n",
    "        width=1000,        \n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(font=dict(family=\"Times New Roman\",size=12),\n",
    "                      xaxis={\"categoryorder\":\"category ascending\"}\n",
    "                     )\n",
    "    \n",
    "    fig.for_each_annotation(lambda x: x.update(text = x.text.replace(\"Period=\", \"\")))\n",
    "    fig.update_yaxes(title_text = \"\", visible = False)\n",
    "    fig.update_xaxes(title_text = \"Topic\")\n",
    "    \n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c409c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barh_chart(df, x, y, title):\n",
    "    \"\"\"\n",
    "    Plot bar chart.\n",
    "    \n",
    "    df = dataframe\n",
    "    x = categorical variable\n",
    "    y = numerical variable \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.bar(\n",
    "        data_frame = df,\n",
    "        x = x,\n",
    "        y = y,\n",
    "        color_discrete_sequence=[\"#03658C\"],\n",
    "        template=\"simple_white\",\n",
    "        orientation = \"h\",\n",
    "        text = x,\n",
    "        width=1000,        \n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(font=dict(family=\"Times New Roman\",size=12),\n",
    "                      yaxis={'categoryorder':'max ascending'},\n",
    "                      title={\n",
    "                          'text': title,\n",
    "                          'y':0.98,\n",
    "                          'x':0.5,\n",
    "                          'xanchor': 'center',\n",
    "                          'yanchor': 'top'}\n",
    "                     )\n",
    "    \n",
    "    fig.update_yaxes(title_text = \"\")\n",
    "    fig.update_xaxes(title_text = \"\", visible = False)\n",
    "    \n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a08afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(df, x, n_bins, title): \n",
    "    \"\"\"\n",
    "    Plot histogram.\n",
    "    \n",
    "    df = dataframe\n",
    "    x = categorical variable\n",
    "    n_bins = bin size \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.histogram(\n",
    "        data_frame=df,\n",
    "        x = x,\n",
    "        marginal= \"box\",\n",
    "        color_discrete_sequence=[\"#03658C\"],\n",
    "        nbins=n_bins,\n",
    "        template=\"simple_white\",\n",
    "        width=1000,        \n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Times New Roman\", \n",
    "        title={\n",
    "            'text': title,\n",
    "            'y':0.95,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'}\n",
    "    )\n",
    "\n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df):\n",
    "    \"\"\"\n",
    "    Plot scatter plot.\n",
    "    \n",
    "    df = dataframe with x and y coordinates \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.scatter(\n",
    "        data_frame = df,\n",
    "        #color = topics,\n",
    "        opacity = 0.5,\n",
    "        title = None,\n",
    "        color_discrete_sequence=[\"#023373\", \"#03588C\", \"#03658C\", \"#6CBAD9\", \"#F2F2F2\" ],\n",
    "        template=\"simple_white\",\n",
    "        orientation = \"h\",\n",
    "        width=1000,        \n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Times New Roman\" \n",
    "    )\n",
    "    \n",
    "    return fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(df, x, y, z):  \n",
    "    \"\"\"\n",
    "    Plot area chart.\n",
    "    \n",
    "    df = dataframe \n",
    "    x = categorical variable\n",
    "    y = numerical variable \n",
    "    z = topics\n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.area(\n",
    "        data_frame = df,\n",
    "        x = x,\n",
    "        y = y,\n",
    "        template = \"simple_white\",\n",
    "        color_discrete_sequence = colors1,\n",
    "        facet_col = z,\n",
    "        facet_col_wrap=2,\n",
    "        facet_row_spacing = 0.1,\n",
    "        height = 1000,\n",
    "        width = 1000\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Times New Roman\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.for_each_annotation(lambda x: x.update(text = x.text.replace(\"variable=\", \"\")))\n",
    "    \n",
    "    fig.update_xaxes(title_text = \"\")\n",
    "    fig.update_yaxes(title_text = \"\")\n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words):\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        fig = px.bar(\n",
    "            x = weights,\n",
    "            y = top_features,\n",
    "            text =np.round(weights, 2),\n",
    "            orientation = \"h\",\n",
    "            color_discrete_sequence=[\"#03658C\"],\n",
    "            template = \"simple_white\", \n",
    "            #title=\"Long-Form Input\",\n",
    "            title = \"Topic \" + str(topic_idx),\n",
    "            height = 400,\n",
    "            width = 400\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.update_layout(\n",
    "            font_family=\"Times New Roman\",\n",
    "            showlegend=False,\n",
    "            yaxis={'categoryorder':'max ascending'},\n",
    "            title={\n",
    "                'y':0.9,\n",
    "                'x':0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top'}\n",
    "        )\n",
    "        \n",
    "        fig.for_each_annotation(lambda x: x.update(text = x.text.replace(\"topic=\", \" \")))\n",
    "        fig.update_yaxes(title_text = \"\")\n",
    "        fig.update_xaxes(title_text = \"\", visible = False)\n",
    "        \n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_2d(df, x, y, document, color, topic_order):\n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        color = color, labels={\"topic\": \"Themen\"},\n",
    "        hover_name = document,\n",
    "        opacity = 0.85,\n",
    "        template=\"simple_white\",\n",
    "        width=800,        \n",
    "        height=500,\n",
    "        color_discrete_sequence=[\"red\", \"green\", \"blue\", \"orange\", \"goldenrod\", \"magenta\"],\n",
    "        category_orders= topic_order\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(showlegend=True)\n",
    "\n",
    "\n",
    "    fig.update_xaxes(visible = False)\n",
    "    fig.update_yaxes(visible = False)\n",
    "\n",
    "    return fig.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_3d(df, x, y, z, color):\n",
    "    fig = px.scatter_3d(\n",
    "        df, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        z=z,\n",
    "        color = color,\n",
    "        #hover_name = \"Topic\",\n",
    "        opacity = 0.85,\n",
    "        template=\"simple_white\",\n",
    "        width=1000,        \n",
    "        height=800,\n",
    "        color_continuous_scale = colors2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "\n",
    "    fig.update_xaxes(visible = False)\n",
    "    fig.update_yaxes(visible = False)\n",
    "\n",
    "    return fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ead78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tm_dist_period(df):\n",
    "    df = df.copy()\n",
    "    df = df.groupby([\"Year\", \"Topic\"]).size()\n",
    "    df = pd.DataFrame(df).reset_index().rename(columns={0:\"Count\"})\n",
    "\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int).astype(str)\n",
    "    df[\"Topic\"] = df[\"Topic\"].astype(str)\n",
    "\n",
    "    conditions = [\n",
    "        (df[\"Year\"] <= \"1997\"),\n",
    "        (df[\"Year\"] >= \"1998\") & (df[\"Year\"] <= \"2005\"),\n",
    "        (df[\"Year\"] >= \"2006\") & (df[\"Year\"] <= \"2013\"),\n",
    "        (df[\"Year\"] >= \"2014\")\n",
    "    ]\n",
    "\n",
    "    titles = [\"a) zwischen 1977 und 1997\",\n",
    "              \"b) zwischen 1998 und 2005\", \n",
    "              \"c) zwischen 2006 und 2013\",\n",
    "              \"d) zwischen 2014 und 2020\"]\n",
    "\n",
    "    df[\"Period\"] = np.select(conditions, titles)\n",
    "    df = df.groupby(by = [\"Period\", \"Topic\"]).agg(Count = (\"Count\", np.sum)).reset_index()\n",
    "    \n",
    "    fig = bar_chart(df, df[\"Topic\"].astype(\"int64\"), df[\"Count\"])\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_distribution(df):\n",
    "    topic_count = pd.DataFrame()\n",
    "\n",
    "    topic_count[\"Topic\"] = df.Topic\n",
    "    topic_count = topic_count.groupby(\"Topic\").agg(\n",
    "        Total_Documents = (\"Topic\", np.size),\n",
    "        Proportion = (\"Topic\", np.size))\n",
    "\n",
    "    topic_count[\"Proportion\"] = topic_count[\"Proportion\"].apply(lambda x: round((x * 100) / len(corpus), 2))\n",
    "\n",
    "    return topic_count.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d142247",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(text, \"Cited by\", 150, \"Histogramm der Anzahl der Zitationen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a307406",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_journals = (text.groupby(by = [\"Source title\"]).size().reset_index(name=\"Totel Documents\"))\n",
    "top_journals = top_journals.sort_values(\"Totel Documents\", ascending=False)\n",
    "\n",
    "top_journals = top_journals[:15]\n",
    "barh_chart(top_journals, y = \"Source title\", x = \"Totel Documents\", title = \"Top 15 Journals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a93ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(text, \"Year\", (len(text[\"Year\"].unique())), \"Histogramm der Veröffentlichungsjahre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08055ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"word_count\"] = corpus[\"Abstract\"].apply(lambda x: len(str(x).split()))\n",
    "histogram(corpus, \"word_count\", 30, \"Histogramm der Anzahl der Wörter in einem Abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e955bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = pd.Series(' '.join(corpus[\"Abstract\"]).split()).value_counts()[:30]\n",
    "top_words = pd.DataFrame(top_words, columns = [\"count\"])\n",
    "\n",
    "barh_chart(top_words, \"count\", top_words.index, \"Top 30 Wörter im Korpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_gram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 3)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    \n",
    "    sum_words = bag_of_words.sum(axis=0).round(2)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "top_words = get_top_n_gram(corpus[\"Abstract\"], 30)\n",
    "df3 = pd.DataFrame(top_words, columns = [\"n_gram\", \"count\"])\n",
    "\n",
    "barh_chart(df3, \"count\", \"n_gram\", \"Top 30 Wörter im Korpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_popularity(model, df):\n",
    "    topic_distribution = df.iloc[:, 5:]\n",
    "    topic_distribution[\"Year\"] = df.Year\n",
    "    \n",
    "    ytime = np.unique(df['Year'])\n",
    "    \n",
    "    topic_distributions_by_year = np.zeros([len(ytime), model.n_components])\n",
    "\n",
    "    topic_distribution_by_year = topic_distribution.groupby(by = \"Year\").sum()\n",
    "    topic_distribution_by_year = topic_distribution_by_year / np.sum(topic_distribution_by_year)\n",
    "    topic_distribution_by_year = topic_distribution_by_year.reset_index().melt(id_vars = \"Year\")\n",
    "    \n",
    "    return topic_distribution_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69707096",
   "metadata": {},
   "source": [
    "## 4. Model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = None\n",
    "n_top_words = 10\n",
    "\n",
    "k_min = 3\n",
    "k_max = 30 + 1\n",
    "k_step = 1\n",
    "\n",
    "max_df = 0.95\n",
    "min_df = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830da127",
   "metadata": {},
   "source": [
    "## 5. Calculate Topic Coherence Cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4bd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%notify\n",
    "def gensim_data(corpus):\n",
    "    from gensim.models.coherencemodel import CoherenceModel\n",
    "    from gensim.corpora.dictionary import Dictionary\n",
    "   \n",
    "    gensim_data = [i.split( ) for i in corpus]\n",
    "    gensim_dict = Dictionary(gensim_data)\n",
    "\n",
    "    gensim_dict.filter_extremes(no_below=3, no_above=0.95, keep_n=5000)\n",
    "\n",
    "    gensim_corpus = [gensim_dict.doc2bow(text) for text in gensim_data]\n",
    "   \n",
    "    return gensim_data, gensim_dict, gensim_corpus\n",
    "gensim_data, gensim_dict, gensim_corpus = gensim_data(corpus[\"Abstract\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4062082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from operator import itemgetter\n",
    "\n",
    "coherence = []\n",
    "n_topic = list(np.arange(k_min, k_max, k_step))\n",
    "for i in n_topic:\n",
    "    gensim_nmfModel = Nmf(\n",
    "        corpus=gensim_corpus,\n",
    "        num_topics=i,\n",
    "        id2word=gensim_dict,\n",
    "        chunksize=2000,\n",
    "        passes=5,\n",
    "        kappa=.1,\n",
    "        minimum_probability=0.01,\n",
    "        w_max_iter=300,\n",
    "        w_stop_condition=0.0001,\n",
    "        h_max_iter=100,\n",
    "        h_stop_condition=0.001,\n",
    "        eval_every=10,\n",
    "        normalize=True,\n",
    "        random_state=1\n",
    "    )\n",
    "  \n",
    "    cm = CoherenceModel(\n",
    "        model=gensim_nmfModel,\n",
    "        texts=gensim_data,\n",
    "        dictionary=gensim_dict,\n",
    "        coherence= \"c_v\"\n",
    "    )\n",
    "  \n",
    "    coherence.append((cm.get_coherence(), i, \"NMF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_coherence_values = pd.DataFrame(coherence, columns = [\"Kohärenzwert Cv\", \"Anzahl der Themen\", \"Algorithmus\"])\n",
    "plot_coherence = line(nmf_coherence_values, \"Anzahl der Themen\", \"Kohärenzwert Cv\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb296ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%notify\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "coherence = []\n",
    "n_topic = list(np.arange(k_min, k_max, k_step))\n",
    "for i in n_topic:\n",
    "    gensim_Model = LdaModel(\n",
    "    corpus=gensim_corpus,\n",
    "    id2word=gensim_dict,\n",
    "    num_topics=i,\n",
    "    eta = 0.1,\n",
    "    alpha = 50/i,\n",
    "    random_state=1,\n",
    "    chunksize=200,\n",
    "    passes=1000,\n",
    "    per_word_topics=True\n",
    "    )\n",
    "\n",
    "    cm = CoherenceModel(\n",
    "        model=gensim_Model,\n",
    "        texts=gensim_data,\n",
    "        dictionary=gensim_dict,\n",
    "        coherence= \"c_v\"\n",
    "    )\n",
    "    \n",
    "    coherence.append((cm.get_coherence(), i, \"LDA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0537b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_coherence_values = pd.DataFrame(coherence, columns = [\"Kohärenzwert Cv\", \"Anzahl der Themen\", \"Algorithmus\"])\n",
    "plot_coherence = line(lda_coherence_values, \"Anzahl der Themen\", \"Kohärenzwert Cv\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ffaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values = pd.concat([nmf_coherence_values, lda_coherence_values], join=\"inner\")\n",
    "line(coherence_values, \"Anzahl der Themen\", \"Kohärenzwert Cv\", \"Algorithmus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cfab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values.drop(\"Anzahl der Themen\", axis = 1).groupby(\"Algorithmus\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b445694",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.shapiro(nmf_coherence_values[\"Kohärenzwert Cv\"]))\n",
    "print(stats.shapiro(lda_coherence_values[\"Kohärenzwert Cv\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(nmf_coherence_values[\"Kohärenzwert Cv\"], lda_coherence_values[\"Kohärenzwert Cv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pg.ttest(nmf_coherence_values[\"Kohärenzwert Cv\"], lda_coherence_values[\"Kohärenzwert Cv\"], alternative = \"greater\", confidence = 0.99, correction=True)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e7ff5",
   "metadata": {},
   "source": [
    "## 6. Latent Dirichlet Allocation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_df=max_df, \n",
    "                                   min_df=min_df, \n",
    "                                   analyzer='word',\n",
    "                                   ngram_range=(1,2), \n",
    "                                   max_features=n_features\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74988901",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_dtm = count_vectorizer.fit_transform(corpus[\"Abstract\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tm = LatentDirichletAllocation(\n",
    "    n_components=6,\n",
    "    doc_topic_prior = (50/6),\n",
    "    topic_word_prior = 0.1,\n",
    "    max_iter=1000, \n",
    "    learning_method='online',   \n",
    "    random_state=1,\n",
    "    batch_size=128, \n",
    "    evaluate_every = -1,\n",
    "    n_jobs = -1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output = lda_tm.fit_transform(bow_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf957db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = pd.DataFrame(\n",
    "    {\"Topic\" : np.argmax(lda_output, axis = 1), \n",
    "     \"Terms\" : corpus[\"Abstract\"], \n",
    "     \"Keywords\" : corpus[\"Index Keywords\"], \n",
    "     \"Title\" : corpus[\"Title\"], \n",
    "     \"DOI\" : corpus[\"DOI\"], \n",
    "     \"Year\" : corpus[\"Year\"], \n",
    "     \"Journal\" : corpus[\"Source title\"]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = lda_df.reset_index()\n",
    "\n",
    "topic_names = [\"Topic \" + str(i) for i in range(lda_tm.n_components)]\n",
    "\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns = topic_names)\n",
    "lda_df = lda_df.join(df_document_topic)\n",
    "\n",
    "lda_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeedd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distribution(lda_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7078e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_names = count_vectorizer.get_feature_names()\n",
    "\n",
    "plot_top_words(lda_tm, feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdf578",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area(topic_popularity(lda_tm, lda_df), \"Year\", \"value\", \"variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6570862",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_dist_period(lda_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028fdb6",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Non-negative Matrix Factorization Topic Modell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b6e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df = max_df, \n",
    "                                   min_df = min_df,\n",
    "                                   max_features = n_features, \n",
    "                                   ngram_range = (1,2)\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dtm = tfidf_vectorizer.fit_transform(corpus[\"Abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1eb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm = NMF(n_components = 6, \n",
    "             random_state=1,\n",
    "             alpha=.1,\n",
    "             solver = \"mu\",\n",
    "             max_iter = 1000,\n",
    "             beta_loss=\"frobenius\",\n",
    "             l1_ratio=.5\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35631ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm = nmf_tm.fit(tfidf_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca461ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = tfidf_vectorizer.transform(corpus[\"Abstract\"])\n",
    "W = nmf_tm.components_\n",
    "H = nmf_tm.fit_transform(V) \n",
    "\n",
    "\n",
    "print(\"Non-negative Matrix Factorization Modell\")\n",
    "print('V = {} x {}'.format(V.shape[0], V.shape[1]))\n",
    "print('W = {} x {}'.format(W.shape[0], W.shape[1]))\n",
    "print('H = {} x {}'.format(H.shape[0], H.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_df = pd.DataFrame(\n",
    "    {\"Topic\" : np.argmax(H, axis = 1), \n",
    "     \"Terms\" : corpus[\"Abstract\"], \n",
    "     \"Keywords\" : corpus[\"Author Keywords\"], \n",
    "     \"Title\" : corpus[\"Title\"], \n",
    "     \"DOI\" : corpus[\"DOI\"], \n",
    "     \"Year\" : corpus[\"Year\"], \n",
    "     \"Journal\" : corpus[\"Source title\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f84f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_df = nmf_df.reset_index()\n",
    "\n",
    "topic_names = [\"Topic \" + str(i) for i in range(nmf_tm.n_components)]\n",
    "\n",
    "df_document_topic = pd.DataFrame(np.round(H, 2), columns = topic_names)\n",
    "\n",
    "nmf_df = nmf_df.join(df_document_topic)\n",
    "nmf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ccbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distribution(nmf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4ee78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "plot_top_words(nmf_tm, feature_names, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ca97a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area(topic_popularity(nmf_tm, nmf_df), \"Year\", \"value\", \"variable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63dfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_dist_period(nmf_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
